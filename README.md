# Scraper Amazon - Spring Boot + Selenium + Docker + Kubernetes â˜ï¸

AplicaÃ§Ã£o Java que realiza scraping de produtos da Amazon Brasil com Selenium e armazena os dados em banco H2. A API Ã© baseada em Spring Boot e estÃ¡ preparada para execuÃ§Ã£o local, containerizada (Docker) ou orquestrada (Kubernetes).

---

## ğŸ§© Tecnologias Utilizadas

- **Java 22** + **Spring Boot 3**
- **Spring Data JPA + H2 Database** (modo memÃ³ria)
- **Selenium WebDriver + WebDriverManager**
- **Gson + Jackson** (serializaÃ§Ã£o JSON)
- **Logback (via SLF4J)** para logging customizado
- **Spring Legacy Web (MVC)**
- **Docker + Docker Compose**
- **Kubernetes (deployment + service)**

---

## ğŸ“ Arquitetura de Classes

- `ScraperController`: Endpoint REST
- `ScraperService`: Orquestra scraping e persistÃªncia
- `SeleniumScraper`: Realiza scraping de fato via Selenium
- `WebDriverManagerUtil`: Gerencia instÃ¢ncia do ChromeDriver
- `WebDriverConfig`: Configura opÃ§Ãµes do navegador
- `ProductRepository`: RepositÃ³rio Spring JPA
- `ProductEntity`: Entidade JPA mapeada para a tabela `products`

---

## ğŸ“¦ ExecuÃ§Ã£o Local

```bash
mvn spring-boot:run
```

Acesse via:
```http
GET http://localhost:8080/api/scraper?max=5
```

---

## ğŸ³ Docker

### Build
```bash
docker build -t amazon-scraper .
```

### Run
```bash
docker run -p 8080:8080 --rm amazon-scraper
```

---

## â˜¸ï¸ Kubernetes

### AplicaÃ§Ã£o
```bash
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
```

### Acesso
```bash
kubectl port-forward svc/amazon-scraper 8080:8080
curl http://localhost:8080/api/scraper?max=5
```

---

## ğŸ“„ Exemplo de JSON extraÃ­do
```json
{
  "title": "8K USB Displayport KVM Switch",
  "price": "R$ 749,90",
  "rating": "4.5 de 5 estrelas",
  "url": "https://www.amazon.com.br/...",
  "executedAt": "2025-04-13 21:28:25"
}
```

---

## ğŸ“œ Spring Legacy

A aplicaÃ§Ã£o utiliza arquitetura baseada em Spring Boot com dependÃªncias compatÃ­veis com projetos legados:

- Utiliza `spring-boot-starter-web` com Spring MVC tradicional (Servlets + Controllers).
- Sem uso de WebFlux ou mÃ³dulos reativos, ideal para manutenÃ§Ã£o em ambientes legados.
- Usa H2 como banco temporÃ¡rio (mas pode ser substituÃ­do facilmente por PostgreSQL ou MySQL).

---

## ğŸ› ï¸ Funcionalidades AvanÃ§adas Implementadas

- Retry com backoff exponencial ao falhar scraping
- WebDriver configurado com Chrome Headless e rotaÃ§Ãµes automÃ¡ticas
- Logs com timestamp e nÃ­vel (scraping.log)
- ExportaÃ§Ã£o automÃ¡tica em JSON (`products_info_*.json`)
- ModularizaÃ§Ã£o com responsabilidades claras
- Suporte a mÃºltiplos produtos com paralelismo (thread-safe)
- Captura da data e hora da extraÃ§Ã£o (`executedAt`)

---

## ğŸ“ Estrutura de DiretÃ³rios

```
scraper-java/
â”œâ”€â”€ src/main/java/
â”‚   â””â”€â”€ org/vinissius/scraper_spring/
â”œâ”€â”€ src/main/resources/
â”‚   â”œâ”€â”€ application.properties
â”‚   â”œâ”€â”€ logback.xml
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â””â”€â”€ service.yaml
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```


## ğŸ“Œ Melhorias Futuras

- Armazenar logs e JSON em bucket S3 ou Azure Blob
- Agendamento automÃ¡tico via `@Scheduled`
- Monitoramento Prometheus + Grafana
- Login bÃ¡sico para autenticar chamadas Ã  API
- Trocar H2 por PostgreSQL persistente

---

## ğŸ§ª Teste de Endpoint
```bash
curl http://localhost:8080/api/scraper?max=5
```

---

## ğŸ‘¨â€ğŸ’» Autor
VinÃ­cius Oliveira  
[LinkedIn](https://www.linkedin.com/in/)

---

MIT License

